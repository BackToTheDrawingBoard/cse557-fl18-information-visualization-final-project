<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="UTF-8">
	<title>Project Documentation</title>
	<link rel="stylesheet" type="text/css" href="./public/css/style.css">
	<link href="https://fonts.googleapis.com/css?family=Arvo" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet">
</head>
<body>
	<div class="titlebar">
		<h1>Topic Model Documentation</h1>
		<div class="padding"></div>
		<a href="./proposal/PeterOlson_proposal.pdf">Project Proposal</a>
		<a href="https://github.com/BackToTheDrawingBoard/cse557-fl18-information-visualization-final-project">Public GitHub Repository</a> 
		<a href="https://github.com/washuvis/topicmodeling">washuvis GitHub Repository</a>
		<a href="./app">Topic Modeling Application</a>
	</div>
	<div class="log-content">
		<!--<div class="log-post">
			<div class="log-header">
				<h2>Lorem Ipsum</h2>
				<p>Nov. 13th, 2018</p>
			</div>
			<div class="log-body">
				<h3>Subtitle</h3> 
				<p>Lorem Ipsum</p>
			</div>
		</div>-->
		<div class="log-post">
			<div class="log-header">
				<h2>Milestone I Process Update</h2>
				<p>Nov. 13th, 2018</p>
			</div>
			<div class="log-body">

				<h3>Overview and Motivation</h3>

				<p>During my junior year, I took Dr. Anupam Basu's Introduction
				to Digital Humanities course, in which we discussed topic
				models.  In our class, we explored a tool called
				<a href="http://vep.cs.wisc.edu/serendip/">Serendip</a>, which
				visualizes topics as a matrix of relationships between texts in
				the corpora and topics.  Then, this semester, I took Dr.
				Neumann's Analysis of Network Data class, and it occurred to me
				that Serendip's matrix presentation of the topic model is
				visually similar to an adjacency matrix.</p>

				<p>I wanted to take a distinctly different approach than
				Serendip, though.  While Serendip focuses on drilling down into
				specific relationships and presenting a large volume of
				information at once, I wanted to focus more on exploring the
				topic-story relationship in a more approachable, intuitive
				manner.</p>
				
				<h3>Questions</h3>
				
				<p>As I'm implementing a different style of topic modeling (LDA
				modeling, this time), I'm becoming more and more curious how
				one can tune the topic models for fast computation and reliable
				convergence.</p>
				
				<p>My existing implementation of a topic-model algorithm is
				strictly random and heuristic.  There is no cleverness in the
				implementation -- it simply assigns words to random topics and
				calls it a day.  LDA randomly distributes words between topics
				with duplicates, then iterates over the data set, processing it
				an arbitrary number of times.  Ideally, by the time the
				modeling is over, the topics have converged towards unique
				terms and the model is stable.</p>

				<p>That process, however, sort of begs the question of what an
				unstable process model would look like.  I'm interested to
				explore that with the implementation of LDA Topic modeling that
				I've pulled into my project.</p>

				<h3>Data</h3>
				
				<p>For my initial corpus, I arbitrarily chose the twenty most
				popular texts on Project Gutenberg, selected from 
				<a href="http://www.gutenberg.org/browse/scores/top">this page</a>. 
				Unfortunately, JavaScript isn't quite as efficient as the C++
				and Python topic modeling implementations that I'm familiar
				with, and it's turned out to be extraordinarily slow to process
				so many records with the LDA algorithm.</p>

				<p>To facilitate faster development, I actually took advantage
				of the flexibility of my approach and turned to analyzing the
				five most recent State of the Union addresses. However, this
				decision turned out to be more informative as to the thesis of
				my project than I had initially anticipated.</p>

				<div class="figure">
					<img src="images/figure1.png">
					<p>Figure 1: A prototype colour-coded network graph of State
					of the Union addresses.</p>
				</div>
				
				<p>As I began working on my prototype with the more
				politically-oriented data set, I had something of a small
				epiphany. In order to stay true to what I intuited the purpose
				of my project to be, I had to actively dissuade myself from
				delving into enhancing the model with functionality specific to
				that data set. For example, colour-coding nodes based on their
				party affiliation, while interesting in the context of a
				politically informed data set, would be nigh-completely
				irrelevant for a data set like the Gutenberg Top 20 that I
				started and finished with.</p>
				
				<p>This intuitive discouragement, however, made little sense in
				the context of the assignment that we, as a class, had been
				given. This disjunction in intent finally crystalized the intent
				of my application. Rather than creating a bespoke visualization
				for a specific set of data, my intention was to create a tool to
				visualize and explore topic models themselves.</p>

				<p>For further development of the data set, it may be worth
				swapping out the Top-20 texts for something smaller.  Song
				lyrics come to mind, as do public addresses, such as
				presidential addresses and the like.  However, given that I'd
				purely swapping one set of raw text files for another, the
				Top-20 corpus is more than sufficient for project development.
				The flexibility of the application to accommodate many different
				kinds of input data is also one of the great strengths of topic
				modeling as a means of distant reading.</p>

				<h3>Exploratory Data Analysis</h3>

				<p>As I've mentioned, I've used topic modeling tools in the
				past, specifically as part of Dr. Anupam Basu's Introduction to
				Digital Humanities class as a means of "distant reading".
				Conveniently enough, though, familiarity with the algorithms
				involved is all that's necessary for analysis of a topic model.
				The rest of the data analysis is tied exclusively in with
				displaying it as whatever sort of visualization one desires.
				Topic models are one of those pesky data structures that's quite
				simple in theory (it's just a list of weights between stories
				and topics, after all) and yet also exceptionally difficult to
				visualize in one's head.</p>
				
				<p>Fortunately, the data itself requires very little
				pre-processing. All that was requried for the Gutenberg Top 20
				was the removal of the Project Gutenberg header and footer from
				the documents after they were retrieved. The State of the Union
				addresses required even less cleanup. Again, this versatality is
				one of the strong points for the design of my application. The
				data set can easily be expanded or altered entirely with a
				single-line modification to the application and minimal
				manipulation of the initial texts.</p>
				
				<h3>Design Evolution</h3>

				<p>The original impetus behind this assignment was to create a
				visual model to frame the relationship between documents in a
				corpus and the topics extrapolated from the corpus. When I was
				at the point of framing my project proposal, the motivation
				towards displaying a topic model as a force-network was simply
				based on the notion that different documents, or stories, have
				different affinities towards different topics.</p>

				<p>The unrefined notion of the force-network for a topic model
				was immediately appealing to me, because the force-network
				facilitated the spacial expression of the "pull" that each topic
				has on each story.  It's exceedingly rare to have a topic model
				wherein a topic has no relation to a story, but topic models can
				often have a story that's drawn particularly strongly to an
				individual topic.</p>

				<div class="figure">
					<img src="images/figure2.png">
					<p>Figure 2: The initial force-network layout with absolute
					equivalence between documents and topics.</p>
				</div>

				<p>With these characteristics in mind, I continued with the
				development of the force-network model. My initial intent was to
				create a visual model that established a visual equivalence
				between the topics and the documents as elements of the network.
				My initial conception of the force-network was as a means of
				establishing visual equivalence between topics and stories. This
				equalizing intent was based on the notion that both data
				structures are fundamentally ordered sets of words, though
				the documents in the data set are created by humans and the
				topics are the results of a data analysis algorithm.</p>
				
				<p>However, as the design progressed, I quickly found that
				framing stories and topics as visual equals quickly dilluted the
				meaning of the topic model to the point of being nigh-useless.
				Without a visual context for the information in the network, the
				network ceased to have any meaning.</p>
				
				<p>My first method of addressing the lack of information was to
				encode the roles of the nodes in the graph with both colour and
				size. Somewhat arbitrarily, topics became green and large,
				whereas documents remained blue and small.</p>

				<div class="figure">
					<img src="images/figure3.png">
					<p>Figure 3: The force-network with topics configured as
					static "force-generators".</p>
				</div>
				
				<p>As the network model matured, I developed the concept of
				having force-generator nodes and force-receiver nodes as a means
				of re-asserting the directed relationship between documents and
				topics. Force-generator nodes (topics) were assigned a fixed
				position based on their order in the list of topics, and
				force-receiver nodes were set in the middle of the graph. d3's
				force-network simulation then handled the distribution of the
				force-receivers and allowed for repositioning of the topic
				nodes.</p>

				<p>This framework of force-generator nodes allowed for a clearer
				expression of hierarchy in the display of the topic model, and
				additionally force the documents into a somewhat logical spacial
				distribution in relation to the topics that they're most
				attracted to.</p>

				<div class="figure">
					<img src="images/figure4.png">
					<p>Figure 4: The force-network with topics visually labeled
					but without the force-generator model.</p>
					<!-- FIXME -->
				</div>

				<h3>Implementation</h3>
				
				<p>Presently, all that's implemented is the initial topic model
				generation.  As I've mentioned above, simply getting the
				algorithms working and producing accessible topics is a
				non-trivial component of this project, and the more time spent
				working on the topic modeling algorithms the smoother the
				resulting interaction with the corpus can be.</p>

				<p>The remaining work is to expose knobs for tuning the topic
				generation parameters, slap the topic model weights into a
				d3 force-network, and display per-story histograms of the topic
				distributions.  Then, of course, polish everything to a suitable
				level of shine.</p>

				<h3>Evaluation</h3>
				
				<p>The biggest improvement that I think I can make going
				forwards is by collecting a different corpus, one composed of
				shorter texts.  Calculating a topic-model of Moby Dick is a
				non-trivial task, and it's more than enough to bring my desktop
				computer to a crawl.</p>
				
				<p>Other than selecting different texts for the corpus, though,
				the remaining work is just grinding out an interface for the
				algorithm I've re-implemented.  I was quite surprised at how
				ill-kept the LDA library that I found on GitHub was, and, while
				I was able to reuse some of the code, I also would up
				re-implementing a large portion of the modeling code to better
				suit the object model of my application.</p>

			</div>
		</div>
	</div>
</body>
</html>
